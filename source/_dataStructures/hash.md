### 散列表的起源？
为了快速地对动态集合进行查找。最好的查找效率在查找树，也是log(n) 的时间复杂度。但在插入数据时，对树的影响比较大。能不能在既保证快速查找的前提下，也有较好的 插入/删除 效率？

### 散列冲突的时候可以怎么做？  
[me] 是不是可以再用一个散列表，对键进行再散列？只要保证散列函数的相干性，应该就可以。然后将新的散列表的位置放在当前散列表的键中。

[me] 如果采用在 碰撞 后重新寻找表内空余空间放置的策略的话，拿到对应的键如何查找？是不是一定需要对该键进行标记其散列次数？

前述理解不对，对散列表的数据结构理解有误。在开放一个散列表空间，然后将某个元素放入该散列表时，要先计算该元素的散列值。最终在存储该元素时，也会存储它的键(散列表存储的就是键值对)。所以在查找一个元素时，首先可以计算到 key 的散列值，找到散列值后去找对应位置上的元素，如果元素的键与待查元素的键不一样，说明它要不不存在，要不被冲突后再散列到了其它位置，因此可以利用散列冲突的解决策略继续寻找，知道确定找不到。


以课程的示例代码为例，散列表的每个元素的时机结构是 数据域+info域。后者指示当前空格内是 空的 或者 被删除 或 有元素。这样可以在元素数据被删除后不破坏其它(被存放时发生冲突且经过了该位置的)数据在被查找时的正确性。(如果直接删掉不以 deleted 标识，下次找另一个散列冲突经过它的元素，就会判断是找不到，实际上还在原来的位置)

为什么对于分离链表散列法，成功查找的平均次数要大于不成功查找？

分离链表法，查找次数降低了，但是在链表上每次查找的开销要大于在开放地址法的查找开销。所以在装填因子较大时性能也不好，尤其链表的长度可能会不均匀。  
这里的关键其实就是链表和数组，在访问时的开销差距有多大？



### insert or merge
如何判断一个数列是经过了 merge_sort 的了？写程序判断，而不是人眼判断 



### 
10 3 5 7 2 6 4 9 0 8 1
10 3 5 7 2 6 4 9 8 0 1
10 3 5 7 2 6 4 0 8 9 1
10 3 5 0 2 6 4 7 8 9 1
10 0 5 3 2 6 4 7 8 9 1
10 1 5 3 2 6 4 7 8 9 0
10 1 5 3 2 0 4 7 8 9 6
10 1 0 3 2 5 4 7 8 9 6
10 1 2 3 0 5 4 7 8 9 6
10 1 2 3 4 5 0 7 8 9 6
10 1 2 3 4 5 6 7 8 9 0
0 1 2 3 4 5 6 7 8 9 10